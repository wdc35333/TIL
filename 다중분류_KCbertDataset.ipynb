{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJumOSbc0_84"
      },
      "source": [
        "# 악플 분류기 - 다중분류\n",
        "- 데이터: https://github.com/smilegate-ai/korean_unsmile_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S766WUh3J_cb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GSgpe1q-Kf6W"
      },
      "outputs": [],
      "source": [
        "# 데이터 불러오기\n",
        "train_df = pd.read_csv(\"/content/unsmile_train_v1.0.tsv\",delimiter='\\t')\n",
        "test_df = pd.read_csv(\"/content/unsmile_valid_v1.0.tsv\", delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "FN35wYipfHTh",
        "outputId": "e9178c2a-9c6a-4ee7-db98-9582e840348b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15005, 12) (3737, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  문장  여성/가족  남성  성소수자  인종/국적  \\\n",
              "0                             일안하는 시간은 쉬고싶어서 그런게 아닐까      0   0     0      0   \n",
              "1  아동성범죄와 페도버는 기록바 끊어져 영원히 고통 받는다. 무슬림 50퍼 근친이다. ...      0   0     0      0   \n",
              "2  루나 솔로앨범 나왔을 때부터 머모 기운 있었음 ㅇㅇ Keep o  doin 진짜 띵...      0   0     0      0   \n",
              "\n",
              "   연령  지역  종교  기타 혐오  악플/욕설  clean  개인지칭  \n",
              "0   0   0   0      0      0      1     0  \n",
              "1   0   0   1      0      0      0     0  \n",
              "2   0   0   0      0      0      1     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13e03a92-cbdf-4c60-9e20-e3038da81dc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타 혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "      <th>개인지칭</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>일안하는 시간은 쉬고싶어서 그런게 아닐까</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>아동성범죄와 페도버는 기록바 끊어져 영원히 고통 받는다. 무슬림 50퍼 근친이다. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>루나 솔로앨범 나왔을 때부터 머모 기운 있었음 ㅇㅇ Keep o  doin 진짜 띵...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13e03a92-cbdf-4c60-9e20-e3038da81dc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13e03a92-cbdf-4c60-9e20-e3038da81dc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13e03a92-cbdf-4c60-9e20-e3038da81dc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "print(train_df.shape, test_df.shape)\n",
        "train_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIEEzkynfSIK"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4GDel_AfVVV"
      },
      "source": [
        "- train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJud5W4lKigh",
        "outputId": "a88d2e7b-b6c2-4652-d5cb-0bc80df09f10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null 값 체크\n",
        "train_df.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hOekkV6Kl1P",
        "outputId": "a56c522d-4d30-4c9d-f3e6-c10cfd866bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15005, 12) 15004\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15004, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 중복 데이터 확인\n",
        "print(train_df.shape, train_df.문장.nunique())\n",
        "\n",
        "# 중복 데이터 제거\n",
        "train_df.drop_duplicates(subset=['문장'], inplace=True)\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du4IN2Ir5XG5",
        "outputId": "90a48be9-f39d-4304-efaa-d29acb8947a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Int64Index([5876, 11942], dtype='int64')\n"
          ]
        }
      ],
      "source": [
        "# 분류가 안되어 있는 데이터 확인\n",
        "print(train_df[train_df.sum(axis=1) == 0].index)\n",
        "\n",
        "# 분류 안되어 있는 데이터 삭제\n",
        "train_df = train_df[train_df.sum(axis=1) != 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv7w5Ra3fq5i"
      },
      "source": [
        "- test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdK75sSwfsuZ",
        "outputId": "777f458c-33e2-4549-8fff-37b2854afa23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Null 값 체크\n",
        "test_df.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmit9Jsdfx0X",
        "outputId": "f14cac66-322c-4448-f9a3-46463a0f762c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3737, 12), 3737)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 중복 데이터 확인\n",
        "test_df.shape, test_df.문장.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "zE28yhj_5ni9",
        "outputId": "fa485d4d-58a5-42c5-9fae-6791cde79861"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ecb5a022-ef1b-4933-9d46-a936b6af7ecf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문장</th>\n",
              "      <th>여성/가족</th>\n",
              "      <th>남성</th>\n",
              "      <th>성소수자</th>\n",
              "      <th>인종/국적</th>\n",
              "      <th>연령</th>\n",
              "      <th>지역</th>\n",
              "      <th>종교</th>\n",
              "      <th>기타 혐오</th>\n",
              "      <th>악플/욕설</th>\n",
              "      <th>clean</th>\n",
              "      <th>개인지칭</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecb5a022-ef1b-4933-9d46-a936b6af7ecf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecb5a022-ef1b-4933-9d46-a936b6af7ecf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecb5a022-ef1b-4933-9d46-a936b6af7ecf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [문장, 여성/가족, 남성, 성소수자, 인종/국적, 연령, 지역, 종교, 기타 혐오, 악플/욕설, clean, 개인지칭]\n",
              "Index: []"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 분류가 안되어 있는 데이터 확인\n",
        "test_df[test_df.sum(axis=1) == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB1t0SEP5zQm"
      },
      "source": [
        "## 텍스트 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3aEp41q54Dt"
      },
      "source": [
        "- train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOokoq_t516o",
        "outputId": "d07480dd-63da-451f-aa25-825bdcddbbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14978, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
        "train_df.문장 = train_df.문장.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ').str.strip()\n",
        "train_df.문장.replace('', np.nan, inplace=True)\n",
        "print(train_df.문장.isna().sum())\n",
        "train_df.dropna(how='any', inplace=True)\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVzaeNqt59MF"
      },
      "source": [
        "- test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkgUd2Vg58WZ",
        "outputId": "7a5438d8-6960-493d-990e-dd63eb30d6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3730, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 한글 이외의 문자는 공백으로 처리하고 strip\n",
        "test_df.문장 = test_df.문장.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ').str.strip()\n",
        "test_df.문장.replace('', np.nan, inplace=True)\n",
        "print(test_df.문장.isna().sum())\n",
        "test_df.dropna(how='any', inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "test_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdHmL6byxeT3"
      },
      "source": [
        "- 데이터 분포"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDjX7UUhxb-q",
        "outputId": "209d1ba1-dffb-4ccf-bf17-44ee44b5ba0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "여성/가족    1599\n",
              "남성       1347\n",
              "성소수자     1140\n",
              "인종/국적    1727\n",
              "연령        603\n",
              "지역       1052\n",
              "종교       1181\n",
              "기타 혐오     569\n",
              "악플/욕설    3141\n",
              "clean    3718\n",
              "개인지칭      315\n",
              "dtype: object"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.sum()[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X8BEKpxx3AM",
        "outputId": "d3c1f619-b1c9-4018-f7b5-7d0c8c69625e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "여성/가족    393\n",
              "남성       334\n",
              "성소수자     280\n",
              "인종/국적    426\n",
              "연령       146\n",
              "지역       260\n",
              "종교       290\n",
              "기타 혐오    134\n",
              "악플/욕설    785\n",
              "clean    930\n",
              "개인지칭      74\n",
              "dtype: object"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.sum()[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1VcQvHKklIY"
      },
      "source": [
        "## 악플 데이터만 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MCZTpWqqjGM6"
      },
      "outputs": [],
      "source": [
        "train_df = train_df[train_df['clean'] ==0]\n",
        "test_df = test_df[test_df['clean'] ==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AABOIa27jGM6"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.iloc[:, :10]\n",
        "test_df = test_df.iloc[:, :10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoQmnmWckpmq"
      },
      "source": [
        "- 이중 레이블 나누기\n",
        "- 레이블 열 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Mg1ive2nkpL9"
      },
      "outputs": [],
      "source": [
        "# 라벨링\n",
        "df = pd.concat([train_df['문장'], train_df.iloc[:, 1:] * range(1, 10)], axis=1)\n",
        "\n",
        "dataset_train = pd.DataFrame()\n",
        "for i in range(1, 10):\n",
        "  data = df.loc[df.iloc[:, i] > 0][['문장', df.columns[i]]]\n",
        "  data.columns = ['문장', '라벨']\n",
        "  dataset_train = pd.concat([dataset_train, data])\n",
        "  \n",
        "  dataset_train.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM54MQK4k6tl"
      },
      "source": [
        "- 오버 샘플링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LHBdQxguktYZ"
      },
      "outputs": [],
      "source": [
        "x = dataset_train['문장'].values.reshape(-1, 1)\n",
        "y = dataset_train.iloc[:, 1:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "daYECe4Ak90r"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "X_resampled, y_resampled = RandomOverSampler(random_state=0).fit_resample(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "QfCCyBM6k-3z",
        "outputId": "4b9244ba-4742-47b1-c161-36b8e7494276"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "counter = Counter(y_resampled)\n",
        "plt.bar(counter.keys(), counter.values())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fmZEr0l1oEG"
      },
      "source": [
        "## 한글 형태소 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5JSig7wwjeac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62486a6-a104-46d9-93be-dd34be728dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 23.65 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 610 kB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 71.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-06-10 04:11:39--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=UxYpSuZWXZnG%2BN8rldjAq3o4PmA%3D&Expires=1654835899&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2022-06-10 04:11:39--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=UxYpSuZWXZnG%2BN8rldjAq3o4PmA%3D&Expires=1654835899&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.28.188\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.28.188|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-06-10 04:11:39 (33.2 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-06-10 04:12:51--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=7Hq1f1BPqNeblr6d3eViMR%2F9xYI%3D&Expires=1654835899&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2022-06-10 04:12:51--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=7Hq1f1BPqNeblr6d3eViMR%2F9xYI%3D&Expires=1654835899&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.140.217\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.140.217|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M   107MB/s    in 0.4s    \n",
            "\n",
            "2022-06-10 04:12:52 (107 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n",
            "문제를 해결해주신 combacsa님 감사합니다.\n"
          ]
        }
      ],
      "source": [
        "# Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rEFvYMqc12vQ"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qVKQQvnc1dw6"
      },
      "outputs": [],
      "source": [
        "mecab = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "90d9dcd719184a06885c64884ddb4fd5",
            "9d306bd131774566b98fe8c293d8fc9d",
            "6c245ddf5124444881aa0c4f0282abcf",
            "d190966efafc41ce8e01af049edccb68",
            "e9f19ecc9c414e1fb8f6f2bb9eb896e8",
            "c08d31bc1ce84569a0e2c996aab5b621",
            "f5a39b8bc9f34aa4801a71ea35e2b964",
            "c2af9599359a4b0b825d63bab52c91dc",
            "a4c7e8b88f4f4d47a6293236b82d733e",
            "c95767750e2241f5b391b8ce0d97089b",
            "39f4c68630074822972926e545df99d2"
          ]
        },
        "id": "d1a73tac2aaT",
        "outputId": "dc79133b-46c3-4a53-f12e-8fce4ae6fef5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28269 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90d9dcd719184a06885c64884ddb4fd5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_data = []\n",
        "for sentence in tqdm(X_resampled):\n",
        "  morphs = mecab.morphs(sentence[0])\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  train_data.append(tmp_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4e199cdf51df4256a099966d1fd665c0",
            "55a67d519a6e4d129836331c4bc748be",
            "4aadd98a9cbd4641926242224450ba44",
            "eb99467f950a4bea9f8f265cb282d549",
            "33dbc24c655f4aa6a4920433abac9795",
            "ebf0d0063296447baaf695d05e3417f2",
            "9b677e63741349919c43228f94ac6979",
            "6da0f4ec34a14888b246ca2f2912a676",
            "f0f472ec537f4d62befeb6aa5ca78d5d",
            "78df959142e14bbe98dde62dfb391d58",
            "70b72a97b7f246249b4c751324c5866c"
          ]
        },
        "id": "s_NJnMypOxY0",
        "outputId": "6a5fabb8-614f-4459-a43b-3d8e208ab770"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11260 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e199cdf51df4256a099966d1fd665c0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "test_data = []\n",
        "for sentence in tqdm(train_df.문장):\n",
        "  morphs = mecab.morphs(sentence)\n",
        "  tmp_X = [word for word in morphs if word not in stopwords]\n",
        "  test_data.append(tmp_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QETCaH3cTqzb"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sG2k08NMhPpK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0KeqSe5QPHlJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ix6-ej1c26NR"
      },
      "outputs": [],
      "source": [
        "# 등장 빈도가 3 미만인 것의 갯수\n",
        "threshold = 3\n",
        "total_cnt = len(t.word_index)   # 단어의 수\n",
        "rare_cnt = 0                    # 등장 빈도가 threshold 보다 작은 단어의 갯수\n",
        "total_freq = 0                  # 훈련 데이터의 전체 단어의 빈도수의 합\n",
        "rare_freq = 0                   # 등장 빈도가 threshold 보다 작은 단어의 등장 빈도수의 합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Fc_Yniiu3LKN"
      },
      "outputs": [],
      "source": [
        "for key, value in t.word_counts.items():\n",
        "  total_freq += value\n",
        "  if value < threshold:\n",
        "    rare_cnt += 1\n",
        "    rare_freq += value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpRyvzQa3MbH",
        "outputId": "61d163d4-ff86-4fd9-a12b-6cfa2c72a486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 16999\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 5923\n",
            "단어 집합에서 희귀 단어의 비율: 34.843226072121894\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.5931996532973676\n"
          ]
        }
      ],
      "source": [
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print(f'등장 빈도가 {threshold - 1}번 이하인 희귀 단어의 수: {rare_cnt}')\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoo8rfzc3cCX",
        "outputId": "509bb290-7729-4d2c-81dd-a8319e0ea762"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17001"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# 모든 단어 사용\n",
        "vocab_size = total_cnt + 2\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jhbvjJoE3nae"
      },
      "outputs": [],
      "source": [
        "t = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "t.fit_on_texts(train_data)\n",
        "X_train = t.texts_to_sequences(train_data)\n",
        "X_test = t.texts_to_sequences(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJDeO7fUT9wK",
        "outputId": "e7a08a8b-2543-4398-a11e-87a9530d31bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74, 18.202341787824118)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# 데이터의 최대/평균 길이\n",
        "max(len(s) for s in X_train), sum(map(len, X_train)) / len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "aYq1T83SUgWD"
      },
      "outputs": [],
      "source": [
        "# 악플 길이를 60으로 설정\n",
        "max_len = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK-Df341Uh8J",
        "outputId": "a59fb5db-aa01-479d-e64c-2a7e9d10d0f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28269, 60), (11260, 60))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqsiqzEZh6Ck",
        "outputId": "75d27337-73d4-4ab6-e472-e0451ffed12f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28269, 9), (11260, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y_train = to_categorical(y_resampled)\n",
        "Y_train = np.delete(Y_train, 0, 1)\n",
        "Y_test = train_df.iloc[:, 1:].values\n",
        "Y_train.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln0RXe-liL9D"
      },
      "source": [
        "## 모델 정의/설정/학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bFRq8MvYiLtM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D, Dropout, Concatenate\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmCT-WN4E6gf"
      },
      "source": [
        "## 셀프 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF8L16qOq-9p"
      },
      "source": [
        "### 멀티 헤드 어텐션\n",
        "- 트랜스포머 인코더의 첫번째 서브층"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "d1yPCxZtE8ak"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "y131InpHE9ye"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads=8):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.embedding_dim = embedding_dim # d_model\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        assert embedding_dim % self.num_heads == 0\n",
        "\n",
        "        self.projection_dim = embedding_dim // num_heads\n",
        "        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n",
        "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
        "\n",
        "    def scaled_dot_product_attention(self, query, key, value):\n",
        "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        logits = matmul_qk / tf.math.sqrt(depth)\n",
        "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "        output = tf.matmul(attention_weights, value)\n",
        "        return output, attention_weights\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # (batch_size, seq_len, embedding_dim)\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "\n",
        "        # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        query = self.split_heads(query, batch_size)  \n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
        "        # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
        "\n",
        "        # (batch_size, seq_len, embedding_dim)\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
        "        outputs = self.dense(concat_attention)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdgKGc1lrVda"
      },
      "source": [
        "### 인코더 설계하기\n",
        "- 두번째 서브칭인 포지션 와이즈 피드 포워드 신경망 추가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BaLUJacxE_En"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(embedding_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
        "             tf.keras.layers.Dense(embedding_dim),]\n",
        "        )\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs) # 첫번째 서브층 : 멀티 헤드 어텐션\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output) # Add & Norm\n",
        "        ffn_output = self.ffn(out1) # 두번째 서브층 : 포지션 와이즈 피드 포워드 신경망\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output) # Add & Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIRp1iN7rcmv"
      },
      "source": [
        "### 포지션 임베딩\n",
        "- 임베딩 층을 사용하되, 위치 벡터 학습하도록 임베딩 층의 첫번째 인자로 단어 집합의 크기가 아니라 문장의 최대 길이를 넣어줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qUAfcMBFFA0h"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos_emb = tf.keras.layers.Embedding(max_len, embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        max_len = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMmiJDrjrsra"
      },
      "source": [
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zNXdyb3CFDuW"
      },
      "outputs": [],
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcxgA6mrs3ty"
      },
      "source": [
        "### 모델 정의/학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "IIv4f5j0s6zT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6pxy9ytGOnQ"
      },
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAfl2tw5FbzJ",
        "outputId": "f7da9475-1df6-4101-8987-62fe4d1917f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 60)]              0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 60, 32)           545952    \n",
            " g (TokenAndPositionEmbeddin                                     \n",
            " g)                                                              \n",
            "                                                                 \n",
            " transformer_block (Transfor  (None, 60, 32)           6464      \n",
            " merBlock)                                                       \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 32)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                660       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 9)                 189       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 553,265\n",
            "Trainable params: 553,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = 32  # 각 단어의 임베딩 벡터의 차원\n",
        "num_heads = 2  # 어텐션 헤드의 수\n",
        "dff = 32  # 포지션 와이즈 피드 포워드 신경망의 은닉층의 크기\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(max_len,))\n",
        "embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
        "x = transformer_block(x)\n",
        "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "outputs = tf.keras.layers.Dense(9, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPlf-xQxFdpp",
        "outputId": "469fc6d6-c404-4225-9f3e-24d4d408be36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "704/707 [============================>.] - ETA: 0s - loss: 1.6237 - accuracy: 0.4289\n",
            "Epoch 1: val_loss improved from inf to 2.20515, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fede94c1250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 14s 13ms/step - loss: 1.6213 - accuracy: 0.4299 - val_loss: 2.2051 - val_accuracy: 0.3154\n",
            "Epoch 2/100\n",
            "703/707 [============================>.] - ETA: 0s - loss: 0.8651 - accuracy: 0.7405\n",
            "Epoch 2: val_loss improved from 2.20515 to 1.70118, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fede94c1250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 9s 13ms/step - loss: 0.8645 - accuracy: 0.7406 - val_loss: 1.7012 - val_accuracy: 0.4381\n",
            "Epoch 3/100\n",
            "707/707 [==============================] - ETA: 0s - loss: 0.5894 - accuracy: 0.8205\n",
            "Epoch 3: val_loss improved from 1.70118 to 1.45883, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fede94c1250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 10s 13ms/step - loss: 0.5894 - accuracy: 0.8205 - val_loss: 1.4588 - val_accuracy: 0.4807\n",
            "Epoch 4/100\n",
            "704/707 [============================>.] - ETA: 0s - loss: 0.4495 - accuracy: 0.8614\n",
            "Epoch 4: val_loss improved from 1.45883 to 1.17514, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fede94c1250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 10s 14ms/step - loss: 0.4492 - accuracy: 0.8614 - val_loss: 1.1751 - val_accuracy: 0.5522\n",
            "Epoch 5/100\n",
            "706/707 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.8785\n",
            "Epoch 5: val_loss improved from 1.17514 to 0.79776, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fede94c1250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 9s 12ms/step - loss: 0.3720 - accuracy: 0.8784 - val_loss: 0.7978 - val_accuracy: 0.7009\n",
            "Epoch 6/100\n",
            "706/707 [============================>.] - ETA: 0s - loss: 0.3217 - accuracy: 0.8876\n",
            "Epoch 6: val_loss did not improve from 0.79776\n",
            "707/707 [==============================] - 6s 8ms/step - loss: 0.3217 - accuracy: 0.8875 - val_loss: 0.8460 - val_accuracy: 0.6816\n",
            "Epoch 7/100\n",
            "700/707 [============================>.] - ETA: 0s - loss: 0.2844 - accuracy: 0.8971\n",
            "Epoch 7: val_loss did not improve from 0.79776\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.2841 - accuracy: 0.8972 - val_loss: 0.8947 - val_accuracy: 0.6800\n",
            "Epoch 8/100\n",
            "707/707 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.9041\n",
            "Epoch 8: val_loss improved from 0.79776 to 0.75997, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fede94c1250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 8s 12ms/step - loss: 0.2574 - accuracy: 0.9041 - val_loss: 0.7600 - val_accuracy: 0.7055\n",
            "Epoch 9/100\n",
            "707/707 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.9048\n",
            "Epoch 9: val_loss did not improve from 0.75997\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.2474 - accuracy: 0.9048 - val_loss: 0.7806 - val_accuracy: 0.6701\n",
            "Epoch 10/100\n",
            "702/707 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9103\n",
            "Epoch 10: val_loss improved from 0.75997 to 0.66565, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fede94c1250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 9s 12ms/step - loss: 0.2293 - accuracy: 0.9105 - val_loss: 0.6657 - val_accuracy: 0.6935\n",
            "Epoch 11/100\n",
            "703/707 [============================>.] - ETA: 0s - loss: 0.2262 - accuracy: 0.9079\n",
            "Epoch 11: val_loss improved from 0.66565 to 0.57509, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fede94c1250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 8s 12ms/step - loss: 0.2264 - accuracy: 0.9079 - val_loss: 0.5751 - val_accuracy: 0.7046\n",
            "Epoch 12/100\n",
            "704/707 [============================>.] - ETA: 0s - loss: 0.2151 - accuracy: 0.9111\n",
            "Epoch 12: val_loss did not improve from 0.57509\n",
            "707/707 [==============================] - 5s 7ms/step - loss: 0.2152 - accuracy: 0.9110 - val_loss: 0.6086 - val_accuracy: 0.7122\n",
            "Epoch 13/100\n",
            "704/707 [============================>.] - ETA: 0s - loss: 0.2038 - accuracy: 0.9128\n",
            "Epoch 13: val_loss did not improve from 0.57509\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.2036 - accuracy: 0.9130 - val_loss: 0.7060 - val_accuracy: 0.6873\n",
            "Epoch 14/100\n",
            "707/707 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9132\n",
            "Epoch 14: val_loss improved from 0.57509 to 0.50486, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fede94c1250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 9s 12ms/step - loss: 0.2007 - accuracy: 0.9132 - val_loss: 0.5049 - val_accuracy: 0.7163\n",
            "Epoch 15/100\n",
            "703/707 [============================>.] - ETA: 0s - loss: 0.1979 - accuracy: 0.9148\n",
            "Epoch 15: val_loss improved from 0.50486 to 0.47967, saving model to best-transforemr-attention.h5py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: best-transforemr-attention.h5py/assets\n",
            "WARNING:absl:<__main__.MultiHeadAttention object at 0x7fede94c1250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r707/707 [==============================] - 8s 12ms/step - loss: 0.1976 - accuracy: 0.9150 - val_loss: 0.4797 - val_accuracy: 0.7239\n",
            "Epoch 16/100\n",
            "704/707 [============================>.] - ETA: 0s - loss: 0.1889 - accuracy: 0.9154\n",
            "Epoch 16: val_loss did not improve from 0.47967\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.1891 - accuracy: 0.9155 - val_loss: 0.4809 - val_accuracy: 0.7191\n",
            "Epoch 17/100\n",
            "704/707 [============================>.] - ETA: 0s - loss: 0.1890 - accuracy: 0.9162\n",
            "Epoch 17: val_loss did not improve from 0.47967\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.1891 - accuracy: 0.9162 - val_loss: 0.5705 - val_accuracy: 0.7076\n",
            "Epoch 18/100\n",
            "702/707 [============================>.] - ETA: 0s - loss: 0.1822 - accuracy: 0.9175\n",
            "Epoch 18: val_loss did not improve from 0.47967\n",
            "707/707 [==============================] - 5s 8ms/step - loss: 0.1821 - accuracy: 0.9175 - val_loss: 0.5254 - val_accuracy: 0.6993\n"
          ]
        }
      ],
      "source": [
        "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model_path = 'best-transforemr-attention.h5py'\n",
        "mc = ModelCheckpoint(model_path, verbose=1, save_best_only=True)\n",
        "es = EarlyStopping(patience=3)\n",
        "\n",
        "history = model.fit(X_train, Y_train, validation_split=0.2,\n",
        "                    batch_size=32, epochs=100, callbacks=[mc, es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e08LhEntJA5e",
        "outputId": "c289a1bf-8db2-4148-9439-f2e9b46fd740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352/352 [==============================] - 2s 4ms/step - loss: 0.1870 - accuracy: 0.9650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18701282143592834, 0.9650088548660278]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "best_model = load_model(model_path)\n",
        "best_model.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4cvmug0JJUF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def sentiment_predict(review, best_model,tokenizer=t, max_len=max_len):\n",
        "    review = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',review).strip()\n",
        "    morphs = mecab.morphs(review)\n",
        "    morphs = [word for word in morphs if word not in stopwords]\n",
        "    encoded = tokenizer.texts_to_sequences([morphs])\n",
        "    padded = pad_sequences(encoded, maxlen=max_len)\n",
        "    score = best_model.predict(padded)\n",
        "    class_text = test_df.columns[1:]\n",
        "\n",
        "    return print(f\"'{review}'\\n {score[0][score.argmax()]*100}%의 확률로 {class_text[score.argmax()]}에 대한 악플입니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5JrmwarFfCL",
        "outputId": "48b8364f-397a-4c25-b22c-efaff2985b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'근데 아프가니스탄은 이슬람권 국가중에서도 거의 막장수준이라    다른국가 히잡안쓰는애들도 꽤 많음'\n",
            " 62.24408149719238%의 확률로 인종/국적에 대한 악플입니다.\n",
            "None\n",
            "문장       근데 아프가니스탄은 이슬람권 국가중에서도 거의 막장수준이라    다른국가 히잡안쓰는...\n",
            "여성/가족                                                    0\n",
            "남성                                                       0\n",
            "성소수자                                                     0\n",
            "인종/국적                                                    1\n",
            "연령                                                       0\n",
            "지역                                                       0\n",
            "종교                                                       0\n",
            "기타 혐오                                                    0\n",
            "악플/욕설                                                    0\n",
            "Name: 1210, dtype: object\n"
          ]
        }
      ],
      "source": [
        "num=1210\n",
        "text = test_df['문장'][num]\n",
        "print(sentiment_predict(text, best_model,tokenizer=t, max_len=max_len))\n",
        "print(test_df.loc[num])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XazWfV3PaMsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "악플분류기_다중분류_확인.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "9f5feb42f08914aecde0ece13ac07afe9f84906579ba918f8c70eb200f669000"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 ('min')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90d9dcd719184a06885c64884ddb4fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d306bd131774566b98fe8c293d8fc9d",
              "IPY_MODEL_6c245ddf5124444881aa0c4f0282abcf",
              "IPY_MODEL_d190966efafc41ce8e01af049edccb68"
            ],
            "layout": "IPY_MODEL_e9f19ecc9c414e1fb8f6f2bb9eb896e8"
          }
        },
        "9d306bd131774566b98fe8c293d8fc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c08d31bc1ce84569a0e2c996aab5b621",
            "placeholder": "​",
            "style": "IPY_MODEL_f5a39b8bc9f34aa4801a71ea35e2b964",
            "value": "100%"
          }
        },
        "6c245ddf5124444881aa0c4f0282abcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2af9599359a4b0b825d63bab52c91dc",
            "max": 28269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4c7e8b88f4f4d47a6293236b82d733e",
            "value": 28269
          }
        },
        "d190966efafc41ce8e01af049edccb68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c95767750e2241f5b391b8ce0d97089b",
            "placeholder": "​",
            "style": "IPY_MODEL_39f4c68630074822972926e545df99d2",
            "value": " 28269/28269 [00:08&lt;00:00, 3015.89it/s]"
          }
        },
        "e9f19ecc9c414e1fb8f6f2bb9eb896e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c08d31bc1ce84569a0e2c996aab5b621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a39b8bc9f34aa4801a71ea35e2b964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2af9599359a4b0b825d63bab52c91dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4c7e8b88f4f4d47a6293236b82d733e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c95767750e2241f5b391b8ce0d97089b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f4c68630074822972926e545df99d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e199cdf51df4256a099966d1fd665c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55a67d519a6e4d129836331c4bc748be",
              "IPY_MODEL_4aadd98a9cbd4641926242224450ba44",
              "IPY_MODEL_eb99467f950a4bea9f8f265cb282d549"
            ],
            "layout": "IPY_MODEL_33dbc24c655f4aa6a4920433abac9795"
          }
        },
        "55a67d519a6e4d129836331c4bc748be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebf0d0063296447baaf695d05e3417f2",
            "placeholder": "​",
            "style": "IPY_MODEL_9b677e63741349919c43228f94ac6979",
            "value": "100%"
          }
        },
        "4aadd98a9cbd4641926242224450ba44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6da0f4ec34a14888b246ca2f2912a676",
            "max": 11260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0f472ec537f4d62befeb6aa5ca78d5d",
            "value": 11260
          }
        },
        "eb99467f950a4bea9f8f265cb282d549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78df959142e14bbe98dde62dfb391d58",
            "placeholder": "​",
            "style": "IPY_MODEL_70b72a97b7f246249b4c751324c5866c",
            "value": " 11260/11260 [00:04&lt;00:00, 2507.59it/s]"
          }
        },
        "33dbc24c655f4aa6a4920433abac9795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebf0d0063296447baaf695d05e3417f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b677e63741349919c43228f94ac6979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6da0f4ec34a14888b246ca2f2912a676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0f472ec537f4d62befeb6aa5ca78d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78df959142e14bbe98dde62dfb391d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b72a97b7f246249b4c751324c5866c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}